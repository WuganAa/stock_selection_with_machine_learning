{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"F:\\\\DeepLearning\\\\Data\"\n",
    "fpath_insample = os.path.join(fpath, \"insample\")\n",
    "fpath_outsample = os.path.join(fpath, \"outsample\")\n",
    "\n",
    "X_train = np.load(os.path.join(fpath_insample, \"X.npy\"))\n",
    "Y_train = np.load(os.path.join(fpath_insample, \"Y.npy\"))\n",
    "X_test = np.load(os.path.join(fpath_outsample, \"X.npy\"))\n",
    "Y_test = np.load(os.path.join(fpath_outsample, \"Y.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70440, 229)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70440,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25500, 229)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25500,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_sample = \"F:\\\\DeepLearning\\\\Data\\\\sample\"\n",
    "\n",
    "X = np.load(os.path.join(fpath_sample, \"X.npy\"))\n",
    "Y = np.load(os.path.join(fpath_sample, \"Y.npy\"))\n",
    "X_train = X[:800,:]\n",
    "Y_train = Y[:800]\n",
    "X_test = X[800:,:]\n",
    "Y_test = Y[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 229)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 229)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LogisticRegression\n",
    "* RandomForest\n",
    "* SupportVectorMachine\n",
    "* DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import model \n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if we begin with empty model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(X_train, Y_train, X_test, Y_test)\n",
    "rf = RandomForest(X_train, Y_train, X_test, Y_test)\n",
    "svm = SupportVectorMachine(X_train, Y_train, X_test, Y_test)\n",
    "dnn = DNN(X_train, Y_train, X_test, Y_test)\n",
    "modelsList = [lg, rf, svm, dnn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if we begin with existent model in \"modelpath\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"F:\\\\DeepLearning\\\\Model\\\\20180929-133417\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(fpath=modelpath)\n",
    "rf = RandomForest(fpath=modelpath)\n",
    "svm = SupportVectorMachine(fpath=modelpath)\n",
    "dnn = DNN(fpath=modelpath)\n",
    "modelsList = [lg, rf, svm, dnn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = os.path.join(\"F:\\\\DeepLearning\\\\Model\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def using_model(model):\n",
    "    print(\"Begin Model: {}\\n\\n\".format(model.type))\n",
    "    Accuracy, Precision, Recall, F1, TPR, FPR, AUC = model.evalution()\n",
    "    print(\"\\nAccuracy, Precision, Recall, F1, TPR, FPR, AUC:\")\n",
    "    print(Accuracy, Precision, Recall, F1, TPR, FPR, AUC,\"\\n\")\n",
    "    \n",
    "    Accuracy, Precision, Recall, F1, TPR, FPR, AUC = model.evalution_with_data(X_test, Y_test)\n",
    "    print(\"\\nAccuracy, Precision, Recall, F1, TPR, FPR, AUC:\")\n",
    "    print(Accuracy, Precision, Recall, F1, TPR, FPR, AUC,\"\\n\")\n",
    "    \n",
    "    print(\"\\nPredict X_test with classified output:\")\n",
    "    print(model.predict(X_test[0:10,:]),\"\\n\")\n",
    "    \n",
    "    print(\"\\nPredict X_test with probability output:\")\n",
    "    print(model.predict_proba(X_test[0:10,:]),\"\\n\")\n",
    "    \n",
    "    model.save_model(modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Model: ModelType.LR\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4484 - acc: 0.9575\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.4479 - acc: 0.9637\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4485 - acc: 0.9637\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.4481 - acc: 0.9587\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4481 - acc: 0.9600\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4483 - acc: 0.9575\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 55us/step - loss: 0.4480 - acc: 0.9562\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.4482 - acc: 0.9625\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4469 - acc: 0.9612\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.4478 - acc: 0.9537\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4482 - acc: 0.9600\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.4481 - acc: 0.9600\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4480 - acc: 0.9637\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 55us/step - loss: 0.4480 - acc: 0.9625\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4479 - acc: 0.9650\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4478 - acc: 0.9650\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.4482 - acc: 0.9575\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4477 - acc: 0.9587\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.4476 - acc: 0.9587\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.4480 - acc: 0.9625\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4474 - acc: 0.9587\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4476 - acc: 0.9612\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.4474 - acc: 0.9625\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.4475 - acc: 0.9550\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4474 - acc: 0.9625\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4482 - acc: 0.9600\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.4476 - acc: 0.9612\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4471 - acc: 0.9625\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.4480 - acc: 0.9600\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 55us/step - loss: 0.4476 - acc: 0.9637\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.4476 - acc: 0.9625\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4471 - acc: 0.9637\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4472 - acc: 0.9575\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4475 - acc: 0.9612\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 55us/step - loss: 0.4477 - acc: 0.9562\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4475 - acc: 0.9587\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4479 - acc: 0.9600\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.4473 - acc: 0.9600\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.4472 - acc: 0.9575\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4478 - acc: 0.9600\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4473 - acc: 0.9600\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4473 - acc: 0.9637\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.4474 - acc: 0.9550\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4468 - acc: 0.9637\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4478 - acc: 0.9625\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4474 - acc: 0.9637\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4469 - acc: 0.9637\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4477 - acc: 0.9600\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.4468 - acc: 0.9637\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.4471 - acc: 0.9600\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4475 - acc: 0.9625\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4469 - acc: 0.9550\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.4474 - acc: 0.9637\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4467 - acc: 0.9587\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4476 - acc: 0.9600\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4475 - acc: 0.9625\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4476 - acc: 0.9612\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4472 - acc: 0.9587\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4475 - acc: 0.9662\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4470 - acc: 0.9600\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4472 - acc: 0.9550\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4471 - acc: 0.9637\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4469 - acc: 0.9625\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4470 - acc: 0.9562\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4471 - acc: 0.9600\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4467 - acc: 0.9650\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4467 - acc: 0.9625\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4465 - acc: 0.9600\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.4476 - acc: 0.9562\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4470 - acc: 0.9662\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4474 - acc: 0.9575\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4470 - acc: 0.9612\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.4464 - acc: 0.9562\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4471 - acc: 0.9612\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4467 - acc: 0.9625\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4470 - acc: 0.9650\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4468 - acc: 0.9612\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.4471 - acc: 0.9650\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4470 - acc: 0.9625\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4469 - acc: 0.9625\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4467 - acc: 0.9612\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.4464 - acc: 0.9600\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4471 - acc: 0.9637\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 45us/step - loss: 0.4466 - acc: 0.9587\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4468 - acc: 0.9625\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4476 - acc: 0.9612\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4469 - acc: 0.9612\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4472 - acc: 0.9600\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4467 - acc: 0.9625\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4464 - acc: 0.9600\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4468 - acc: 0.9612\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4466 - acc: 0.9550\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4475 - acc: 0.9625\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4470 - acc: 0.9575\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 55us/step - loss: 0.4473 - acc: 0.9625\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4463 - acc: 0.9600\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4465 - acc: 0.9612\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4468 - acc: 0.9625\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4466 - acc: 0.9575\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4467 - acc: 0.9612\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9351351351351351 0.8969072164948454 0.9775280898876404 0.935483870967742 0.9775280898876404 0.10416666666666667 0.9727586610486891 \n",
      "\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9351351351351351 0.8969072164948454 0.9775280898876404 0.935483870967742 0.9775280898876404 0.10416666666666667 0.9727586610486891 \n",
      "\n",
      "\n",
      "Predict X_test with classified output:\n",
      "[1. 1. 0. 0. 0. 1. 1. 0. 0. 0.] \n",
      "\n",
      "\n",
      "Predict X_test with probability output:\n",
      "[0.74584746 0.7872648  0.08660159 0.03937557 0.3795646  0.64737576\n",
      " 0.85222936 0.26067266 0.35231087 0.410941  ] \n",
      "\n",
      "The LogisticRegression Model save in \n",
      "  F:\\DeepLearning\\Model\\20180929-133417\\LR_model_weights.h5 and \n",
      "  F:\\DeepLearning\\Model\\20180929-133417\\LR_model_architecture.json\n"
     ]
    }
   ],
   "source": [
    "using_model(modelsList[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Model: ModelType.RF\n",
      "\n",
      "\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9945945945945946 0.9888888888888889 1.0 0.9944134078212291 1.0 0.010416666666666666 0.9997366573033708 \n",
      "\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9945945945945946 0.9888888888888889 1.0 0.9944134078212291 1.0 0.010416666666666666 0.9947916666666667 \n",
      "\n",
      "\n",
      "Predict X_test with classified output:\n",
      "[1. 1. 0. 0. 0. 1. 1. 0. 0. 0.] \n",
      "\n",
      "\n",
      "Predict X_test with probability output:\n",
      "[0.98993048 0.99993048 0.         0.         0.03992063 0.99989459\n",
      " 0.99993048 0.         0.         0.        ] \n",
      "\n",
      "The RandomForest Model save in \n",
      "  F:\\DeepLearning\\Model\\20180929-133417\\RF_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "using_model(modelsList[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SupportVectorMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Model: ModelType.LR\n",
      "\n",
      "\n",
      "[LibSVM]\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9297297297297298 0.9 0.9606741573033708 0.9293478260869567 0.9606741573033708 0.09895833333333333 0.9801615168539326 \n",
      "\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9216216216216216 0.8669950738916257 0.9887640449438202 0.9238845144356955 0.9887640449438202 0.140625 0.9240695224719101 \n",
      "\n",
      "\n",
      "Predict X_test with classified output:\n",
      "[1. 1. 0. 0. 0. 1. 1. 0. 0. 0.] \n",
      "\n",
      "\n",
      "Predict X_test with probability output:\n",
      "[9.99989506e-01 9.99997393e-01 1.50222530e-05 1.00000010e-07\n",
      " 1.54053772e-03 9.70890949e-01 9.96168200e-01 5.81753585e-03\n",
      " 2.92655048e-03 7.00377376e-02] \n",
      "\n",
      "The SupportVectorMachine Model save in \n",
      "  F:\\DeepLearning\\Model\\20180929-133417\\SVM_model.pkl\n"
     ]
    }
   ],
   "source": [
    "using_model(modelsList[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Model: ModelType.DNN\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 666us/step - loss: 3.0309 - acc: 0.6425\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.7169 - acc: 0.7925\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 84us/step - loss: 2.6130 - acc: 0.8438\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 2.5139 - acc: 0.8725\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 2.4695 - acc: 0.8712\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 2.3782 - acc: 0.8962\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 116us/step - loss: 2.3363 - acc: 0.8937\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 2.2643 - acc: 0.9237\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 2.2351 - acc: 0.9262\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 91us/step - loss: 2.1781 - acc: 0.9400\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 89us/step - loss: 2.1349 - acc: 0.9350\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 2.0675 - acc: 0.9562\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 2.0624 - acc: 0.9450\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 2.0390 - acc: 0.9412\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 1.9911 - acc: 0.9537\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9305 - acc: 0.9650\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9107 - acc: 0.9500\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 1.8858 - acc: 0.9575\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 1.8227 - acc: 0.9750\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8498 - acc: 0.9487\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 89us/step - loss: 1.8074 - acc: 0.9562\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.7584 - acc: 0.9737\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 88us/step - loss: 1.7039 - acc: 0.9875\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 92us/step - loss: 1.6702 - acc: 0.9762\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 92us/step - loss: 1.6538 - acc: 0.9800\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 1.6286 - acc: 0.9787\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.6028 - acc: 0.9850\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 1.5798 - acc: 0.9750\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 91us/step - loss: 1.5581 - acc: 0.9725\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 92us/step - loss: 1.5403 - acc: 0.9762\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 91us/step - loss: 1.4880 - acc: 0.9900\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.4882 - acc: 0.9762\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.4521 - acc: 0.9850\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.4277 - acc: 0.9837\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.4022 - acc: 0.9900\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 1.3913 - acc: 0.9837\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.3674 - acc: 0.9825\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.3453 - acc: 0.9862\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 1.3296 - acc: 0.9812\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 92us/step - loss: 1.3076 - acc: 0.9825\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.2986 - acc: 0.9787\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 88us/step - loss: 1.2553 - acc: 0.9925\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 1.2478 - acc: 0.9875\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 90us/step - loss: 1.2265 - acc: 0.9825\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 89us/step - loss: 1.2079 - acc: 0.9862\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 1.1910 - acc: 0.9825\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.1716 - acc: 0.9812\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.1377 - acc: 0.9962\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 90us/step - loss: 1.1189 - acc: 0.9962\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 90us/step - loss: 1.1045 - acc: 0.9950\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 1.0840 - acc: 0.9950\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 92us/step - loss: 1.0746 - acc: 0.9850\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 1.0798 - acc: 0.9837\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 90us/step - loss: 1.0476 - acc: 0.9925\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 1.0346 - acc: 0.9875\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 79us/step - loss: 1.0197 - acc: 0.9887\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 1.0065 - acc: 0.9875\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.9835 - acc: 0.9912\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.9841 - acc: 0.9837\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.9660 - acc: 0.9887\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.9363 - acc: 0.9925\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.9241 - acc: 0.9912\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.9049 - acc: 0.9962\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.8922 - acc: 0.9925\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.8780 - acc: 0.9950\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.8627 - acc: 0.9962\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.8533 - acc: 0.9962\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.8456 - acc: 0.9875\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.8339 - acc: 0.9937\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.8134 - acc: 0.9950\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.8184 - acc: 0.9837\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.8027 - acc: 0.9900\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.7765 - acc: 0.9975\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.7658 - acc: 0.9950\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.7554 - acc: 0.9937\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 0.7465 - acc: 0.9912\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.7362 - acc: 0.9950\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.7156 - acc: 0.9987\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.7085 - acc: 0.9937\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.7021 - acc: 0.9950\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.6950 - acc: 0.9912\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.6926 - acc: 0.9887\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.6742 - acc: 0.9900\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 87us/step - loss: 0.6638 - acc: 0.9925\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.6626 - acc: 0.9887\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.6610 - acc: 0.9912\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.6400 - acc: 0.9962\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.6164 - acc: 0.9987\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 0.6248 - acc: 0.9912\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.6144 - acc: 0.9912\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.5979 - acc: 0.9937\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.6019 - acc: 0.9887\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.6153 - acc: 0.9825\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5728 - acc: 0.9937\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5677 - acc: 0.9950\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5608 - acc: 0.9912\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.5550 - acc: 0.9950\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.5469 - acc: 0.9912\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.5352 - acc: 0.9950\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.5277 - acc: 0.9937\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9864864864864865 0.9779005524861878 0.9943820224719101 0.9860724233983287 0.9943820224719101 0.020833333333333332 0.9935334737827715 \n",
      "\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9864864864864865 0.9779005524861878 0.9943820224719101 0.9860724233983287 0.9943820224719101 0.020833333333333332 0.9935334737827715 \n",
      "\n",
      "\n",
      "Predict X_test with classified output:\n",
      "[1. 1. 0. 0. 0. 1. 1. 0. 0. 0.] \n",
      "\n",
      "\n",
      "Predict X_test with probability output:\n",
      "[9.9919492e-01 9.9954528e-01 3.8374605e-04 4.8170894e-04 3.8063345e-03\n",
      " 9.9954236e-01 9.9953580e-01 1.1547910e-03 1.7957713e-03 1.5238719e-03] \n",
      "\n",
      "The DNN Model save in \n",
      "  F:\\DeepLearning\\Model\\20180929-133417\\DNN_model_weights.h5 and \n",
      "  F:\\DeepLearning\\Model\\20180929-133417\\DNN_model_architecture.json\n"
     ]
    }
   ],
   "source": [
    "using_model(modelsList[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"F:\\\\DeepLearning\\\\Model\\\\20180929-141303\\\\results.pkl\", \"rb\") as file:\n",
    "    results = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
