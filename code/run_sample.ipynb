{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"F:\\\\DeepLearning\\\\Data\"\n",
    "fpath_insample = os.path.join(fpath, \"insample\")\n",
    "fpath_outsample = os.path.join(fpath, \"outsample\")\n",
    "\n",
    "X_train = np.load(os.path.join(fpath_insample, \"X.npy\"))\n",
    "Y_train = np.load(os.path.join(fpath_insample, \"Y.npy\"))\n",
    "X_test = np.load(os.path.join(fpath_outsample, \"X.npy\"))\n",
    "Y_test = np.load(os.path.join(fpath_outsample, \"Y.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70440, 229)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70440,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25500, 229)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25500,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_sample = \"F:\\\\DeepLearning\\\\Data\\\\sample\"\n",
    "\n",
    "X = np.load(os.path.join(fpath_sample, \"X.npy\"))\n",
    "Y = np.load(os.path.join(fpath_sample, \"Y.npy\"))\n",
    "X_train = X[:800,:]\n",
    "Y_train = Y[:800]\n",
    "X_test = X[800:,:]\n",
    "Y_test = Y[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 229)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 229)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LogisticRegression\n",
    "* RandomForest\n",
    "* SupportVectorMachine\n",
    "* DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import model \n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if we begin with empty model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(X_train, Y_train, X_test, Y_test)\n",
    "rf = RandomForest(X_train, Y_train, X_test, Y_test)\n",
    "svm = SupportVectorMachine(X_train, Y_train, X_test, Y_test)\n",
    "dnn = DNN(X_train, Y_train, X_test, Y_test)\n",
    "modelsList = [lg, rf, svm, dnn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if we begin with existent model in \"modelpath\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"F:\\\\DeepLearning\\\\Model\\\\20180929-133417\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(fpath=modelpath)\n",
    "rf = RandomForest(fpath=modelpath)\n",
    "svm = SupportVectorMachine(fpath=modelpath)\n",
    "dnn = DNN(fpath=modelpath)\n",
    "modelsList = [lg, rf, svm, dnn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = os.path.join(\"F:\\\\DeepLearning\\\\Model\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def using_model(model):\n",
    "    print(\"Begin Model: {}\\n\\n\".format(model.type))\n",
    "    Accuracy, Precision, Recall, F1, TPR, FPR, AUC = model.evalution()\n",
    "    print(\"\\nAccuracy, Precision, Recall, F1, TPR, FPR, AUC:\")\n",
    "    print(Accuracy, Precision, Recall, F1, TPR, FPR, AUC,\"\\n\")\n",
    "    \n",
    "    Accuracy, Precision, Recall, F1, TPR, FPR, AUC = model.evalution_with_data(X_test, Y_test)\n",
    "    print(\"\\nAccuracy, Precision, Recall, F1, TPR, FPR, AUC:\")\n",
    "    print(Accuracy, Precision, Recall, F1, TPR, FPR, AUC,\"\\n\")\n",
    "    \n",
    "    print(\"\\nPredict X_test with classified output:\")\n",
    "    print(model.predict(X_test[0:10,:]),\"\\n\")\n",
    "    \n",
    "    print(\"\\nPredict X_test with probability output:\")\n",
    "    print(model.predict_proba(X_test[0:10,:]),\"\\n\")\n",
    "    \n",
    "    model.save_model(modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Model: ModelType.LR\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 0s 362us/step - loss: 0.8226 - acc: 0.7363\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.7119 - acc: 0.8737\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6372 - acc: 0.9150\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.5850 - acc: 0.9387\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.5524 - acc: 0.9400\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.5302 - acc: 0.9350\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.5129 - acc: 0.9612\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.5016 - acc: 0.9475\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.4922 - acc: 0.9500\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.4853 - acc: 0.9575\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4812 - acc: 0.9562\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4771 - acc: 0.9537\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4739 - acc: 0.9575\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4718 - acc: 0.9512\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4703 - acc: 0.9587\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4694 - acc: 0.9587\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4676 - acc: 0.9525\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.4655 - acc: 0.9612\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4650 - acc: 0.9600\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4647 - acc: 0.9550\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4627 - acc: 0.9587\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.4627 - acc: 0.9587\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4618 - acc: 0.9537\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4610 - acc: 0.9500\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4602 - acc: 0.9537\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4598 - acc: 0.9650\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4600 - acc: 0.9562\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4592 - acc: 0.9587\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4587 - acc: 0.9612\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4584 - acc: 0.9587\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 55us/step - loss: 0.4577 - acc: 0.9612\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4581 - acc: 0.9537\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.4578 - acc: 0.9612\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4572 - acc: 0.9562\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4565 - acc: 0.9587\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4568 - acc: 0.9587\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.4561 - acc: 0.9612\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4565 - acc: 0.9612\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4558 - acc: 0.9600\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4556 - acc: 0.9600\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4554 - acc: 0.9650\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.4561 - acc: 0.9525\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4554 - acc: 0.9587\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.4552 - acc: 0.9537\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4553 - acc: 0.9625\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.4551 - acc: 0.9575\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4551 - acc: 0.9612\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4544 - acc: 0.9562\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4545 - acc: 0.9650\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.4547 - acc: 0.9575\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4543 - acc: 0.9600\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4544 - acc: 0.9550\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4534 - acc: 0.9575\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4541 - acc: 0.9575\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4533 - acc: 0.9612\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4529 - acc: 0.9550\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4538 - acc: 0.9587\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4537 - acc: 0.9575\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4532 - acc: 0.9575\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4537 - acc: 0.9612\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.4533 - acc: 0.9637\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4531 - acc: 0.9537\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.4526 - acc: 0.9600\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.4526 - acc: 0.9562\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4526 - acc: 0.9562\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4529 - acc: 0.9550\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4530 - acc: 0.9587\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4527 - acc: 0.9575\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4533 - acc: 0.9625\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.4523 - acc: 0.9575\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4528 - acc: 0.9587\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4523 - acc: 0.9575\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4525 - acc: 0.9550\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4524 - acc: 0.9612\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4524 - acc: 0.9587\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4521 - acc: 0.9537\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.4519 - acc: 0.9587\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4521 - acc: 0.9550\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4514 - acc: 0.9637\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4518 - acc: 0.9575\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.4517 - acc: 0.9575\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4523 - acc: 0.9587\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4513 - acc: 0.9587\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 47us/step - loss: 0.4512 - acc: 0.9600\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4517 - acc: 0.9625\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4524 - acc: 0.9637\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4511 - acc: 0.9625\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4518 - acc: 0.9587\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4510 - acc: 0.9487\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4516 - acc: 0.9650\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4516 - acc: 0.9537\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.4516 - acc: 0.9612\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4511 - acc: 0.9562\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4509 - acc: 0.9612\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4507 - acc: 0.9512\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4511 - acc: 0.9575\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4500 - acc: 0.9612\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4503 - acc: 0.9575\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4514 - acc: 0.9587\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4510 - acc: 0.9525\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9378378378378378 0.9057591623036649 0.9719101123595506 0.9376693766937669 0.9719101123595506 0.09375 0.9730220037453183 \n",
      "\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9378378378378378 0.9057591623036649 0.9719101123595506 0.9376693766937669 0.9719101123595506 0.09375 0.9730220037453183 \n",
      "\n",
      "\n",
      "Predict X_test with classified output:\n",
      "[1. 1. 0. 0. 0. 1. 1. 0. 0. 0.] \n",
      "\n",
      "\n",
      "Predict X_test with probability output:\n",
      "[0.7091513  0.77372116 0.07582279 0.03318183 0.36970213 0.62172383\n",
      " 0.8352809  0.23324905 0.33412358 0.4063767 ] \n",
      "\n",
      "The LogisticRegression Model save in \n",
      "  F:\\DeepLearning\\Model\\20180929-145549\\LR_model_weights.h5 and \n",
      "  F:\\DeepLearning\\Model\\20180929-145549\\LR_model_architecture.json\n"
     ]
    }
   ],
   "source": [
    "using_model(modelsList[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Model: ModelType.RF\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9945945945945946 0.9888888888888889 1.0 0.9944134078212291 1.0 0.010416666666666666 0.9997073970037453 \n",
      "\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9945945945945946 0.9888888888888889 1.0 0.9944134078212291 1.0 0.010416666666666666 0.9947916666666667 \n",
      "\n",
      "\n",
      "Predict X_test with classified output:\n",
      "[1. 1. 0. 0. 0. 1. 1. 0. 0. 0.] \n",
      "\n",
      "\n",
      "Predict X_test with probability output:\n",
      "[0.99200149 0.99923482 0.         0.         0.03997481 0.9999491\n",
      " 0.9999491  0.         0.         0.        ] \n",
      "\n",
      "The RandomForest Model save in \n",
      "  F:\\DeepLearning\\Model\\20180929-145549\\RF_model.pkl\n"
     ]
    }
   ],
   "source": [
    "using_model(modelsList[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SupportVectorMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Model: ModelType.SVM\n",
      "\n",
      "\n",
      "[LibSVM]\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9297297297297298 0.9 0.9606741573033708 0.9293478260869567 0.9606741573033708 0.09895833333333333 0.9801615168539326 \n",
      "\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9216216216216216 0.8669950738916257 0.9887640449438202 0.9238845144356955 0.9887640449438202 0.140625 0.9240695224719101 \n",
      "\n",
      "\n",
      "Predict X_test with classified output:\n",
      "[1. 1. 0. 0. 0. 1. 1. 0. 0. 0.] \n",
      "\n",
      "\n",
      "Predict X_test with probability output:\n",
      "[9.99986377e-01 9.99996505e-01 1.97228445e-05 1.00000010e-07\n",
      " 1.81696418e-03 9.68966171e-01 9.95709092e-01 6.65320324e-03\n",
      " 3.40073709e-03 7.50821971e-02] \n",
      "\n",
      "The SupportVectorMachine Model save in \n",
      "  F:\\DeepLearning\\Model\\20180929-145549\\SVM_model.pkl\n"
     ]
    }
   ],
   "source": [
    "using_model(modelsList[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Model: ModelType.DNN\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 638us/step - loss: 2.9472 - acc: 0.6513\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 2.6443 - acc: 0.8238\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.5959 - acc: 0.8400\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 2.4826 - acc: 0.8638\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 2.4139 - acc: 0.8850\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 2.3813 - acc: 0.8975\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 84us/step - loss: 2.3174 - acc: 0.8975\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2364 - acc: 0.9287\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.2285 - acc: 0.9175\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.1782 - acc: 0.9262\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 91us/step - loss: 2.1335 - acc: 0.9300\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 2.1092 - acc: 0.9237\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.0618 - acc: 0.9412\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 90us/step - loss: 2.0220 - acc: 0.9412\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 1.9713 - acc: 0.9550\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9269 - acc: 0.9612\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 1.9038 - acc: 0.9562\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 1.8751 - acc: 0.9525\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 140us/step - loss: 1.8413 - acc: 0.9550\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8057 - acc: 0.9687\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 105us/step - loss: 1.7788 - acc: 0.9662\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 89us/step - loss: 1.7384 - acc: 0.9687\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6970 - acc: 0.9825\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6803 - acc: 0.9750\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 79us/step - loss: 1.6508 - acc: 0.9712\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 84us/step - loss: 1.6339 - acc: 0.9625\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 1.6140 - acc: 0.9725\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 1.5789 - acc: 0.9787\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 1.5406 - acc: 0.9800\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 1.5294 - acc: 0.9750\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 91us/step - loss: 1.5144 - acc: 0.9712\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 1.4936 - acc: 0.9737\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 84us/step - loss: 1.4555 - acc: 0.9750\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.4224 - acc: 0.9850\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 1.4321 - acc: 0.9712\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 90us/step - loss: 1.3920 - acc: 0.9800\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 1.3552 - acc: 0.9887\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 1.3283 - acc: 0.9875\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 1.3133 - acc: 0.9862\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 1.2840 - acc: 0.9900\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 1.2908 - acc: 0.9750\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 1.2638 - acc: 0.9837\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 89us/step - loss: 1.2449 - acc: 0.9787\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 89us/step - loss: 1.2287 - acc: 0.9787\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 1.2247 - acc: 0.9787\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 1.1951 - acc: 0.9775\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 1.1640 - acc: 0.9862\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 1.1475 - acc: 0.9850\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 89us/step - loss: 1.1210 - acc: 0.9875\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 1.1052 - acc: 0.9912\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 1.0898 - acc: 0.9887\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 1.0674 - acc: 0.9975\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 1.0702 - acc: 0.9800\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 1.0414 - acc: 0.9887\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.0244 - acc: 0.9900\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.0208 - acc: 0.9875\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.9959 - acc: 0.989 - 0s 100us/step - loss: 1.0004 - acc: 0.9850\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.9730 - acc: 0.9937\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.9928 - acc: 0.9850\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.9631 - acc: 0.9850\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.9387 - acc: 0.9875\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.9328 - acc: 0.9875\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 91us/step - loss: 0.9191 - acc: 0.9862\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 89us/step - loss: 0.8871 - acc: 0.9950\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.8819 - acc: 0.9887\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.8671 - acc: 0.9887\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.8579 - acc: 0.9900\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.8531 - acc: 0.9862\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.8185 - acc: 0.9950\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.8075 - acc: 0.9950\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.8002 - acc: 0.9912\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.7855 - acc: 0.9925\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.7778 - acc: 0.9950\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.7644 - acc: 0.9925\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.7674 - acc: 0.9862\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.7372 - acc: 0.9962\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.7385 - acc: 0.9900\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.7132 - acc: 0.9950\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.7246 - acc: 0.9900\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.7130 - acc: 0.9875\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 94us/step - loss: 0.7214 - acc: 0.9762\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 92us/step - loss: 0.6909 - acc: 0.9875\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 105us/step - loss: 0.6862 - acc: 0.9812\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.6782 - acc: 0.9862\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.6680 - acc: 0.9862\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.6515 - acc: 0.9887\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.6280 - acc: 0.9937\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.6255 - acc: 0.9912\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.6219 - acc: 0.9887\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 84us/step - loss: 0.6070 - acc: 0.9925\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.6013 - acc: 0.9912\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.5950 - acc: 0.9875\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.6099 - acc: 0.9800\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5719 - acc: 0.9937\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.5630 - acc: 0.9950\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.5597 - acc: 0.9912\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.5499 - acc: 0.9912\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5450 - acc: 0.9912\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 81us/step - loss: 0.5408 - acc: 0.9925\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.5350 - acc: 0.9887\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9864864864864865 0.9779005524861878 0.9943820224719101 0.9860724233983287 0.9943820224719101 0.020833333333333332 0.993065308988764 \n",
      "\n",
      "\n",
      "Accuracy, Precision, Recall, F1, TPR, FPR, AUC:\n",
      "0.9864864864864865 0.9779005524861878 0.9943820224719101 0.9860724233983287 0.9943820224719101 0.020833333333333332 0.993065308988764 \n",
      "\n",
      "\n",
      "Predict X_test with classified output:\n",
      "[1. 1. 0. 0. 0. 1. 1. 0. 0. 0.] \n",
      "\n",
      "\n",
      "Predict X_test with probability output:\n",
      "[9.9965584e-01 9.9947041e-01 1.2308987e-03 2.9316230e-04 7.1185296e-03\n",
      " 9.9913990e-01 9.9875224e-01 1.3205487e-03 2.3381228e-03 2.0709084e-03] \n",
      "\n",
      "The DNN Model save in \n",
      "  F:\\DeepLearning\\Model\\20180929-145549\\DNN_model_weights.h5 and \n",
      "  F:\\DeepLearning\\Model\\20180929-145549\\DNN_model_architecture.json\n"
     ]
    }
   ],
   "source": [
    "using_model(modelsList[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
